{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Download do repositório: Clojure"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Primeiro devemos realizar o download do programa Clojure usando o repositório defects4J instalado no servidor Lucy.\n",
    "O comando abaixo efetua o download da ferramenta na pasta: **adilsonTeste**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "``` bash\n",
    "/home/sin5022-adm/defects4j/framework/bin/defects4j checkout -p Closure -v 18f -w /home/evosuite/adilsonTeste/Clojure_18_fixed\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para realizar o download da versão com bug usamos o mesmo comando com o parâmetro v, como abaixo:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "``` bash\n",
    "/home/sin5022-adm/defects4j/framework/bin/defects4j checkout -p Closure -v 18b -w /home/evosuite/adilsonTeste/Clojure_18_bug\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Geração de testes automatizada"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vale ressaltar que o parâmetro -A força a execucao sobre todas as classes de interesse (de acordo com a doc) o tempo de execução de cada caso foi aproximadamente de 4h após adicionar o parâmetro -A."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Criteria: branch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "``` bash\n",
    "nohup /home/sin5022-adm/defects4j/framework/bin/run_evosuite.pl -p Closure -v 18b -c branch -A -o /home/evosuite/adilsonTeste/outputTeste/ -n 1 -t /home/evosuite/adilsonTeste/Clojure_18_bug/ &\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Criteria: weakmutation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "``` bash\n",
    "nohup /home/sin5022-adm/defects4j/framework/bin/run_evosuite.pl -p Closure -v 18b -c weakmutation -A -o /home/evosuite/adilsonTeste/outputTeste/ -n 2 -t /home/evosuite/adilsonTeste/Clojure_18_bug/ &\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Criteria: strongmutation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "``` bash\n",
    "nohup /home/sin5022-adm/defects4j/framework/bin/run_evosuite.pl -p Closure -v 18b -c strongmutation -A -o /home/evosuite/adilsonTeste/outputTeste/ -n 3 -t /home/evosuite/adilsonTeste/Clojure_18_bug/ &\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vale ressaltar que o comando acima gera os testes, executa os testes sobre a classe defeituosa, calcula a cobertura entre outras informações que serão relatadas abaixo. Cada execução gerou um arquivo de log: i) Closure.18b.branch.1.log (1 Mb); ii) Closure.18b.weakmutation.2.log (1 Mb) ; iii) Closure.18b.strongmutation.3.log ( 120 Mb ocorreu muita exception, o stacktrace foi o responsável por esse tamanho todo) onde são armazenadas as informações sobre a execução.\n",
    "\n",
    "Foi construído um parser para extrair a informação desses logs, como não teho acesso root no servidor (para instalar pacotes python) executei o parser em minha máquina local, segue código do parser:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def parse_evosuite_log_file(path):\n",
    "     \n",
    "     df_log_evo = pd.DataFrame(columns=('class_name',\n",
    "                                        'number_of_goals',\n",
    "                                        'number_of_tests',\n",
    "                                        'length_of_testes',\n",
    "                                        'ga_zero_fitness',\n",
    "                                        'ga_max_time',\n",
    "                                        'ga_shutdown_test_writer',\n",
    "                                        'test_suit_mutation_score',\n",
    "                                        'time_spent_to_execute_tests',\n",
    "                                        'test_suit_coverage',\n",
    "                                        'num_coverage_goals',\n",
    "                                        'criterion',\n",
    "                                        'coverage_of_criterion',\n",
    "                                        'search_finished_after',\n",
    "                                        'num_generations',\n",
    "                                        'num_statements',   \n",
    "                                        'best_ind_fitness',\n",
    "                                        'permissions',\n",
    "                                        'warnings',\n",
    "                                        'exceptions'\n",
    "                                        ))\n",
    "     class_name = None\n",
    "     number_of_goals = None\n",
    "     number_of_tests = None\n",
    "     length_of_testes = None\n",
    "     ga_zero_fitness = None\n",
    "     ga_max_time = None\n",
    "     ga_shutdown_test_writer = None\n",
    "     test_suit_mutation_score = None\n",
    "     time_spent_to_execute_tests = None\n",
    "     test_suit_coverage = None\n",
    "     num_coverage_goals = None\n",
    "     criterion = None\n",
    "     coverage_of_criterion = None\n",
    "     search_finished_after = None\n",
    "     num_generations = None\n",
    "     num_statements    = None\n",
    "     best_ind_fitness = None\n",
    "     permissions = '' \n",
    "     warnings = ''\n",
    "     exceptions = ''\n",
    "     \n",
    "     \n",
    "     marcacaoPermissao = False  \n",
    "     marcacaoExceptions = False  \n",
    "     \n",
    "     with open(path) as fp:  \n",
    "         \n",
    "       line = fp.readline()\n",
    "       cnt = 1\n",
    "       while line:\n",
    "           \n",
    "           #warnings\n",
    "           if(line.find(\"WARN\") != -1):\n",
    "               warnings = warnings + line.split(\"WARN\")[1].strip() + \"\\n //\"\n",
    "\n",
    "           #exceptions\n",
    "           if( marcacaoExceptions == True or line.find( \"ERROR\") != -1 ):\n",
    "               marcacaoExceptions = True\n",
    "               \n",
    "               #Acabou a descricao de erro\n",
    "               if( str(line[0]).find('*') == 0 and line.find( \"ERROR\") == -1 ):\n",
    "                   marcacaoExceptions = False\n",
    "                   \n",
    "               if(str(line[0]).find('*') != 0):\n",
    "                   exceptions = exceptions + line + \" // \"\n",
    "                   \n",
    "               \n",
    "           if( marcacaoPermissao == True or line.find( \"Permissions denied during test execution\") != -1 ):\n",
    "               marcacaoPermissao = True\n",
    "               \n",
    "               #Acabou a descricao de erro\n",
    "               if( str(line[0]).find('*') == 0 and line.find( \"Permissions denied during test execution\") == -1 ):\n",
    "                   marcacaoPermissao = False\n",
    "                   \n",
    "               if(str(line[0]).find('*') != 0):\n",
    "                   permissions = permissions + line + \" // \"\n",
    "           \n",
    "           if(line.find(\"Going to generate test cases for class:\") != -1):\n",
    "               l = line.strip().split(\"class:\")[1]\n",
    "               class_name = l.strip()\n",
    "           \n",
    "           if(line.find(\"Total number of goals\") != -1):\n",
    "               l = line.strip().split(\"goals:\")\n",
    "               number_of_goals = l[1].split(\":\")[0].strip()\n",
    "\n",
    "           if(line.find(\"tests with total length\") != -1):\n",
    "               l = line.strip().split(\" tests with total length \")\n",
    "               number_of_tests = l[0].replace('* Generated ','').split(\":\")[0].strip()               \n",
    "               length_of_testes = l[1].strip()\n",
    "               \n",
    "           #GA-Budget\n",
    "           if(line.find(\"ZeroFitness\") != -1):\n",
    "               l = line.strip().split(\":\")\n",
    "               ga_zero_fitness = l[1].strip()\n",
    "               \n",
    "           if(line.find(\"MaxTime\") != -1):\n",
    "               l = line.strip().split(\":\")\n",
    "               ga_max_time = l[1].strip()\n",
    "           \n",
    "           if(line.find(\"ShutdownTestWriter\") != -1):\n",
    "               l = line.strip().split(\":\")\n",
    "               ga_shutdown_test_writer = l[1].strip()\n",
    "           \n",
    "           if(line.find(\"Resulting test suite's mutation score\") != -1):\n",
    "               l = line.strip().split(\"score:\")\n",
    "               test_suit_mutation_score = l[1].strip()\n",
    "\n",
    "           if(line.find(\"Time spent executing tests\") != -1):\n",
    "               l = line.strip().split(\"tests:\")\n",
    "               time_spent_to_execute_tests = l[1].strip()\n",
    "           \n",
    "           if(line.find(\"Resulting test suite's coverage\") != -1):\n",
    "               l = line.strip().split(\"coverage:\")\n",
    "               test_suit_coverage = l[1].strip()\n",
    "            \n",
    "           if(line.find(\"Number of covered goals\") != -1):\n",
    "               l = line.strip().split(\"goals:\")\n",
    "               num_coverage_goals = l[1].split(\":\")[0].strip()\n",
    "               \n",
    "           if(line.find(\"Coverage of criterion\") != -1):\n",
    "               l = line.strip().split(\"criterion\")\n",
    "               criterion = l[1].split(\":\")[0].strip()\n",
    "               coverage_of_criterion = l[1].split(\":\")[1].strip()\n",
    "                \n",
    "           if(line.find(\"Search finished after\") != -1):              \n",
    "               #Quebra em 3 blocos de informacao\n",
    "               l = line.strip().split(\", \")\n",
    "\n",
    "               #tempo de busca\n",
    "               l0tmp = l[0].split(\" and \")\n",
    "\n",
    "               #tempo\n",
    "               search_finished_after = l0tmp[0].split(\"after \")[1].strip()\n",
    "\n",
    "               #geracoes\n",
    "               num_generations = l0tmp[1].split(\" generations\")[0].strip()\n",
    "               \n",
    "               #statements\n",
    "               l1tmp = l[1].split(\" \")\n",
    "               num_statements = l1tmp[0].strip()\n",
    "               \n",
    "               #individual fitness\n",
    "               l2tmp = l[2].split(\": \")\n",
    "               best_ind_fitness = l2tmp[1].strip()\n",
    "               \n",
    "               \n",
    "           #Linha de erros de permissão\n",
    "\n",
    "           if(line.find(\"Done\") != -1):\n",
    "               #add to dataframe\n",
    "               df_log_evo = df_log_evo.append({\n",
    "                                                'class_name':class_name,\n",
    "                                                'number_of_goals':number_of_goals,\n",
    "                                                'number_of_tests':number_of_tests,\n",
    "                                                'length_of_testes':length_of_testes,\n",
    "                                                'ga_zero_fitness':ga_zero_fitness,\n",
    "                                                'ga_max_time':ga_max_time,\n",
    "                                                'ga_shutdown_test_writer':ga_shutdown_test_writer,\n",
    "                                                'test_suit_mutation_score':test_suit_mutation_score,\n",
    "                                                'time_spent_to_execute_tests':time_spent_to_execute_tests,\n",
    "                                                'test_suit_coverage':test_suit_coverage,\n",
    "                                                'num_coverage_goals':num_coverage_goals,\n",
    "                                                'criterion':criterion,\n",
    "                                                'coverage_of_criterion':coverage_of_criterion,\n",
    "                                                'search_finished_after':search_finished_after,\n",
    "                                                'num_generations':num_generations,\n",
    "                                                'num_statements':num_statements,   \n",
    "                                                'best_ind_fitness':best_ind_fitness,\n",
    "                                                'permissions':permissions,\n",
    "                                                'warnings':warnings,\n",
    "                                                'exceptions':exceptions\n",
    "                                           }, ignore_index=True)\n",
    "                \n",
    "               class_name = None\n",
    "               number_of_goals = None\n",
    "               number_of_tests = None\n",
    "               length_of_testes = None\n",
    "               ga_zero_fitness = None\n",
    "               ga_max_time = None\n",
    "               ga_shutdown_test_writer = None\n",
    "               test_suit_mutation_score = None\n",
    "               time_spent_to_execute_tests = None\n",
    "               test_suit_coverage = None\n",
    "               num_coverage_goals = None\n",
    "               criterion = None\n",
    "               coverage_of_criterion = None\n",
    "               search_finished_after = None\n",
    "               num_generations = None\n",
    "               num_statements    = None\n",
    "               best_ind_fitness = None\n",
    "               permissions = ''\n",
    "               warnings = ''\n",
    "               exceptions = ''\n",
    "            \n",
    "           line = fp.readline()\n",
    "           cnt += 1\n",
    "    \n",
    "     return(df_log_evo)\n",
    "pass\n",
    "\n",
    "#gerar o csv compactado dos logs.\n",
    "##Branch\n",
    "#path = \"Closure.18b.branch.1.log\"\n",
    "#config_evo_run = parse_evosuite_log_file(path)\n",
    "#config_evo_run.to_csv('parseado_branch.csv',sep = ';')\n",
    "\n",
    "\n",
    "#weakmutation\n",
    "#path = \"Closure.18b.weakmutation.2.log\"\n",
    "#config_evo_run = parse_evosuite_log_file(path)\n",
    "#config_evo_run.to_csv('parseado_weakmutation.csv',sep = ';')\n",
    "\n",
    "\n",
    "#strongmutation #apontar para o desktop eh muit grande coisa de 116Mb\n",
    "#path = \"Closure.18b.strongmutation.3.log\"\n",
    "#config_evo_run = parse_evosuite_log_file(path)\n",
    "#config_evo_run.to_csv('parseado_strongmutation_no_error.csv',sep = ';')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O output dessas 3 chamadas são 3 arquivos csv com os dados tabulados."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Análise de Resultados da geração e execução dos testes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Abaixo podemos ver o código para sumarizar os csvs permitindo um overview das execuções:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "#Conventions for the pd command line\n",
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.width', 100)\n",
    "\n",
    "\n",
    "def analisa_csv(path_csv):\n",
    "    \n",
    "    print(\"=====================================================\")\n",
    "    print(\"=====================================================\")\n",
    "    print(\"=====================================================\")\n",
    "    \n",
    "    branchcsv = pd.read_csv(path_csv, sep = ';')\n",
    "    \n",
    "    #remove o index\n",
    "    branchcsv = branchcsv.drop(['Unnamed: 0'],axis = 1)\n",
    "    \n",
    "    print(\"Número de classes criadas teste: {}\".format(branchcsv.shape[0]))\n",
    "    print(\"Número de atributos das classes criadas teste: {}\".format(branchcsv.shape[1]))\n",
    "    print(\"Total de casos de teste criados para todas as classes: {}\".format(branchcsv.number_of_tests.sum()))\n",
    "    print(\"Média de testes criados por classe: {}\".format( round(branchcsv.number_of_tests.sum()/branchcsv.shape[0], 2) ))\n",
    "    print(\"Tamanho médio(num statements) dos casos de testes criados: {}\".format( round(branchcsv.length_of_testes.mean(), 2) ))\n",
    "    print(\"Número de classes cujos testes geraram warning: {}\".format( round(branchcsv.warnings.count(), 2) ))\n",
    "    print(\"Número de classes cujos testes geraram exceptions: {}\".format( round(branchcsv.exceptions.count(), 2) ))\n",
    "    print(\"Número de classes cujos testes tiveram problemas de permissão: {}\".format( round(branchcsv.permissions.count(), 2) ))\n",
    "    \n",
    "    print(\"=======================================================================\")\n",
    "    \n",
    "    notNatest_suit_mutation_score = branchcsv[branchcsv.test_suit_mutation_score.notnull()].copy(deep = True)\n",
    "    Natest_suit_mutation_score = branchcsv[branchcsv.test_suit_mutation_score.isna()].copy(deep = True)\n",
    "    notNatest_suit_mutation_score['test_suit_mutation_score_noPercent'] = notNatest_suit_mutation_score.test_suit_mutation_score.str.replace('%','')\n",
    "    \n",
    "    notNatest_suit_mutation_score.test_suit_mutation_score_noPercent = notNatest_suit_mutation_score.test_suit_mutation_score_noPercent.astype(int)\n",
    "    print(\"max mutation score: {}\".format(notNatest_suit_mutation_score.test_suit_mutation_score_noPercent.max()))\n",
    "    print(\"min mutation score: {}\".format(notNatest_suit_mutation_score.test_suit_mutation_score_noPercent.min()))\n",
    "    print(\"mean mutation score: {}\".format(round(notNatest_suit_mutation_score.test_suit_mutation_score_noPercent.mean(),2)))\n",
    "    print(\"number of NaN: {}\".format(Natest_suit_mutation_score.test_suit_mutation_score.isna().sum()))\n",
    "    \n",
    "    print(\"=======================================================================\")\n",
    "    \n",
    "    notNatime_spent_to_execute_tests = branchcsv[branchcsv.time_spent_to_execute_tests.notnull()].copy(deep = True)\n",
    "    Natime_spent_to_execute_tests = branchcsv[branchcsv.time_spent_to_execute_tests.isna()].copy(deep = True)\n",
    "    notNatime_spent_to_execute_tests['time_spent_to_execute_tests_no_unity'] = notNatime_spent_to_execute_tests['time_spent_to_execute_tests'].str.replace('ms','')\n",
    "    notNatime_spent_to_execute_tests.time_spent_to_execute_tests_no_unity = notNatime_spent_to_execute_tests.time_spent_to_execute_tests_no_unity.astype(int)\n",
    "    \n",
    "    print(\"max time_spent_to_execute_tests: {} (seg)\".format(notNatime_spent_to_execute_tests.time_spent_to_execute_tests_no_unity.max()/1000))\n",
    "    print(\"min time_spent_to_execute_tests: {} (seg)\".format(notNatime_spent_to_execute_tests.time_spent_to_execute_tests_no_unity.min()/1000))\n",
    "    print(\"mean time_spent_to_execute_tests: {} (seg)\".format(round(notNatime_spent_to_execute_tests.time_spent_to_execute_tests_no_unity.mean()/1000),2))\n",
    "    print(\"number of NaN: {}\".format(Natime_spent_to_execute_tests.time_spent_to_execute_tests.isna().sum()))\n",
    "        \n",
    "    #Limpeza\n",
    "    print(\"=====================================================\")\n",
    "    notNatest_suit_coverage = branchcsv[branchcsv.test_suit_coverage.notnull()].copy(deep = True)\n",
    "    Natest_suit_coverage = branchcsv[branchcsv.test_suit_coverage.isna()].copy(deep = True)\n",
    "    notNatest_suit_coverage['test_suit_coverage_no_unity'] = notNatest_suit_coverage['test_suit_coverage'].str.replace('%','')\n",
    "    notNatest_suit_coverage.test_suit_coverage_no_unity = notNatest_suit_coverage.test_suit_coverage_no_unity.astype(int)\n",
    "    \n",
    "    print(\"max test_suit_coverage: {} (%)\".format(notNatest_suit_coverage.test_suit_coverage_no_unity.max()))\n",
    "    print(\"min test_suit_coverage: {} (%)\".format(notNatest_suit_coverage.test_suit_coverage_no_unity.min()))\n",
    "    print(\"mean test_suit_coverage: {} (%)\".format(round(notNatest_suit_coverage.test_suit_coverage_no_unity.mean(),2)))\n",
    "    print(\"number of NaN: {}\".format(Natest_suit_coverage.test_suit_coverage.isna().sum()))\n",
    "    print(\"=====================================================\")\n",
    "    \n",
    "    #Limpeza\n",
    "    notNacoverage_of_criterion = branchcsv[branchcsv.coverage_of_criterion.notnull()].copy(deep = True)\n",
    "    Nacoverage_of_criterion = branchcsv[branchcsv.coverage_of_criterion.isna()].copy(deep = True)\n",
    "\n",
    "    notNacoverage_of_criterion['coverage_of_criterion_no_unity'] = notNacoverage_of_criterion['coverage_of_criterion'].str.replace('%','')\n",
    "    notNacoverage_of_criterion['coverage_of_criterion_no_unity'] = notNacoverage_of_criterion['coverage_of_criterion_no_unity'].str.replace(' \\(no goals\\)','')\n",
    "    notNacoverage_of_criterion.coverage_of_criterion_no_unity = notNacoverage_of_criterion.coverage_of_criterion_no_unity.astype(int)\n",
    "    \n",
    "    \n",
    "    print(\"max coverage_of_criterion_no_unity: {} (%)\".format(notNacoverage_of_criterion.coverage_of_criterion_no_unity.max()))\n",
    "    print(\"min coverage_of_criterion_no_unity: {} (%)\".format(notNacoverage_of_criterion.coverage_of_criterion_no_unity.min()))\n",
    "    print(\"mean coverage_of_criterion_no_unity: {} (%)\".format(round(notNacoverage_of_criterion.coverage_of_criterion_no_unity.mean(),2)))\n",
    "    print(\"number of NaN: {}\".format(Nacoverage_of_criterion.coverage_of_criterion.isna().sum()))\n",
    "    \n",
    "    print(\"=====================================================\")\n",
    "    \n",
    "    #\n",
    "    print(\"GA - métricas:\")\n",
    "    notNasearch_finished_after = branchcsv[branchcsv.search_finished_after.notnull()].copy(deep = True)\n",
    "    Nasearch_finished_after = branchcsv[branchcsv.search_finished_after.isna()].copy(deep = True)\n",
    "    \n",
    "    notNasearch_finished_after['search_finished_after_no_unity'] = notNasearch_finished_after['search_finished_after'].str.replace('s','')\n",
    "    notNasearch_finished_after.search_finished_after_no_unity = notNasearch_finished_after.search_finished_after_no_unity.astype(int)\n",
    "\n",
    "    print(\"=====================================================\")\n",
    "    print(\"max search_finished_after_no_unity: {} (s)\".format(notNasearch_finished_after.search_finished_after_no_unity.max()))\n",
    "    print(\"min search_finished_after_no_unity: {} (s)\".format(notNasearch_finished_after.search_finished_after_no_unity.min()))\n",
    "    print(\"mean search_finished_after_no_unity: {} (s)\".format(round(notNasearch_finished_after.search_finished_after_no_unity.mean(),2)))\n",
    "    print(\"number of NaN: {}\".format(Nasearch_finished_after.search_finished_after.isna().sum()))\n",
    "    \n",
    "    print(\"=====================================================\")\n",
    "    notNanum_generations = branchcsv[branchcsv.num_generations.notnull()].copy(deep = True)\n",
    "    Nanum_generations = branchcsv[branchcsv.num_generations.isna()].copy(deep = True)\n",
    "\n",
    "\n",
    "    print(\"max num_generations: {}\".format(notNanum_generations.num_generations.max()))\n",
    "    print(\"min num_generations: {}\".format(notNanum_generations.num_generations.min()))\n",
    "    print(\"mean num_generations: {}\".format(round(notNanum_generations.num_generations.mean(),2)))\n",
    "    print(\"number of NaN: {}\".format(Nanum_generations.num_generations.isna().sum()))\n",
    "    \n",
    "    print(\"=====================================================\")\n",
    "    notNanum_statements = branchcsv[branchcsv.num_statements.notnull()].copy(deep = True)\n",
    "    Nanum_statements = branchcsv[branchcsv.num_statements.isna()].copy(deep = True)\n",
    "    \n",
    "    print(\"max num_statements: {}\".format(notNanum_statements.num_statements.max()))\n",
    "    print(\"min num_statements: {}\".format(notNanum_statements.num_statements.min()))\n",
    "    print(\"mean num_statements: {}\".format(round(notNanum_statements.num_statements.mean(),2)))\n",
    "    print(\"number of NaN: {}\".format(Nanum_statements.num_statements.isna().sum()))\n",
    "    \n",
    "    print(\"=====================================================\")\n",
    "    notNabest_ind_fitness = branchcsv[branchcsv.best_ind_fitness.notnull()].copy(deep = True)\n",
    "    Nabest_ind_fitness = branchcsv[branchcsv.best_ind_fitness.isna()].copy(deep = True)\n",
    "    \n",
    "    print(\"max best_ind_fitness: {}\".format(round(notNabest_ind_fitness.best_ind_fitness.max(),2)))\n",
    "    print(\"min best_ind_fitness: {}\".format(notNabest_ind_fitness.best_ind_fitness.min()))\n",
    "    print(\"mean best_ind_fitness: {}\".format(round(notNabest_ind_fitness.best_ind_fitness.mean(),2)))\n",
    "    print(\"number of NaN: {}\".format(Nabest_ind_fitness.best_ind_fitness.isna().sum()))\n",
    "    \n",
    "    print(\"=====================================================\")\n",
    "    print(\"=====================================================\")\n",
    "    print(\"=====================================================\")\n",
    "    print(\"Tempo Geral\")\n",
    "    \n",
    "    #Tempo total rodando testes: converter para horas\n",
    "    print(\"sum time_spent_to_execute_tests: {} (horas)\".format(round( notNatime_spent_to_execute_tests.time_spent_to_execute_tests_no_unity.sum()/(1000*60*60),2 ) ) ) \n",
    "    \n",
    "    #Tempo total de pesquisa do GA:\n",
    "    print(\"sum search_finished_after_no_unity: {} (horas)\".format(round( notNasearch_finished_after.search_finished_after_no_unity.sum()/(60*60),2)))\n",
    "\n",
    "    print(\"=====================================================\")\n",
    "    print(\"=====================================================\")\n",
    "    print(\"=====================================================\")\n",
    "\n",
    "pass\n",
    "\n",
    "branchcsv = 'parseado_branch.csv'\n",
    "weakcsv = 'parseado_weakmutation.csv'\n",
    "strongcsv = 'parseado_strongmutation_no_error.csv'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resultados: branch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=====================================================\n",
      "=====================================================\n",
      "=====================================================\n",
      "Número de classes criadas teste: 159\n",
      "Número de atributos das classes criadas teste: 20\n",
      "Total de casos de teste criados para todas as classes: 3260\n",
      "Média de testes criados por classe: 20.5\n",
      "Tamanho médio(num statements) dos casos de testes criados: 76.21\n",
      "Número de classes cujos testes geraram warning: 144\n",
      "Número de classes cujos testes geraram exceptions: 6\n",
      "Número de classes cujos testes tiveram problemas de permissão: 60\n",
      "=======================================================================\n",
      "max mutation score: 100\n",
      "min mutation score: 0\n",
      "mean mutation score: 54.37\n",
      "number of NaN: 0\n",
      "=======================================================================\n",
      "max time_spent_to_execute_tests: 112.905 (seg)\n",
      "min time_spent_to_execute_tests: 0.0 (seg)\n",
      "mean time_spent_to_execute_tests: 33.0 (seg)\n",
      "number of NaN: 0\n",
      "=====================================================\n",
      "max test_suit_coverage: 100 (%)\n",
      "min test_suit_coverage: 0 (%)\n",
      "mean test_suit_coverage: 71.14 (%)\n",
      "number of NaN: 0\n",
      "=====================================================\n",
      "max coverage_of_criterion_no_unity: 100 (%)\n",
      "min coverage_of_criterion_no_unity: 0 (%)\n",
      "mean coverage_of_criterion_no_unity: 70.5 (%)\n",
      "number of NaN: 0\n",
      "=====================================================\n",
      "GA - métricas:\n",
      "=====================================================\n",
      "max search_finished_after_no_unity: 124 (s)\n",
      "min search_finished_after_no_unity: 0 (s)\n",
      "mean search_finished_after_no_unity: 63.78 (s)\n",
      "number of NaN: 0\n",
      "=====================================================\n",
      "max num_generations: 4341\n",
      "min num_generations: 0\n",
      "mean num_generations: 482.23\n",
      "number of NaN: 0\n",
      "=====================================================\n",
      "max num_statements: 541723\n",
      "min num_statements: 0\n",
      "mean num_statements: 87473.14\n",
      "number of NaN: 0\n",
      "=====================================================\n",
      "max best_ind_fitness: 1046.32\n",
      "min best_ind_fitness: 0.0\n",
      "mean best_ind_fitness: 59.78\n",
      "number of NaN: 0\n",
      "=====================================================\n",
      "=====================================================\n",
      "=====================================================\n",
      "Tempo Geral\n",
      "sum time_spent_to_execute_tests: 1.45 (horas)\n",
      "sum search_finished_after_no_unity: 2.82 (horas)\n",
      "=====================================================\n",
      "=====================================================\n",
      "=====================================================\n"
     ]
    }
   ],
   "source": [
    "analisa_csv(branchcsv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resultados: weakcsv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=====================================================\n",
      "=====================================================\n",
      "=====================================================\n",
      "Número de classes criadas teste: 160\n",
      "Número de atributos das classes criadas teste: 20\n",
      "Total de casos de teste criados para todas as classes: 2749.0\n",
      "Média de testes criados por classe: 17.18\n",
      "Tamanho médio(num statements) dos casos de testes criados: 131.52\n",
      "Número de classes cujos testes geraram warning: 144\n",
      "Número de classes cujos testes geraram exceptions: 9\n",
      "Número de classes cujos testes tiveram problemas de permissão: 55\n",
      "=======================================================================\n",
      "max mutation score: 100\n",
      "min mutation score: 0\n",
      "mean mutation score: 54.35\n",
      "number of NaN: 1\n",
      "=======================================================================\n",
      "max time_spent_to_execute_tests: 350.642 (seg)\n",
      "min time_spent_to_execute_tests: 0.0 (seg)\n",
      "mean time_spent_to_execute_tests: 29.0 (seg)\n",
      "number of NaN: 1\n",
      "=====================================================\n",
      "max test_suit_coverage: 100 (%)\n",
      "min test_suit_coverage: 0 (%)\n",
      "mean test_suit_coverage: 68.53 (%)\n",
      "number of NaN: 1\n",
      "=====================================================\n",
      "max coverage_of_criterion_no_unity: 100 (%)\n",
      "min coverage_of_criterion_no_unity: 0 (%)\n",
      "mean coverage_of_criterion_no_unity: 67.77 (%)\n",
      "number of NaN: 1\n",
      "=====================================================\n",
      "GA - métricas:\n",
      "=====================================================\n",
      "max search_finished_after_no_unity: 168 (s)\n",
      "min search_finished_after_no_unity: 0 (s)\n",
      "mean search_finished_after_no_unity: 75.16 (s)\n",
      "number of NaN: 1\n",
      "=====================================================\n",
      "max num_generations: 3844.0\n",
      "min num_generations: 0.0\n",
      "mean num_generations: 282.83\n",
      "number of NaN: 1\n",
      "=====================================================\n",
      "max num_statements: 345623.0\n",
      "min num_statements: 0.0\n",
      "mean num_statements: 58274.58\n",
      "number of NaN: 1\n",
      "=====================================================\n",
      "max best_ind_fitness: 6950.77\n",
      "min best_ind_fitness: 0.0\n",
      "mean best_ind_fitness: 328.62\n",
      "number of NaN: 1\n",
      "=====================================================\n",
      "=====================================================\n",
      "=====================================================\n",
      "Tempo Geral\n",
      "sum time_spent_to_execute_tests: 1.3 (horas)\n",
      "sum search_finished_after_no_unity: 3.32 (horas)\n",
      "=====================================================\n",
      "=====================================================\n",
      "=====================================================\n"
     ]
    }
   ],
   "source": [
    "analisa_csv(weakcsv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resultados: strongcsv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=====================================================\n",
      "=====================================================\n",
      "=====================================================\n",
      "Número de classes criadas teste: 149\n",
      "Número de atributos das classes criadas teste: 20\n",
      "Total de casos de teste criados para todas as classes: 2859.0\n",
      "Média de testes criados por classe: 19.19\n",
      "Tamanho médio(num statements) dos casos de testes criados: 226.02\n",
      "Número de classes cujos testes geraram warning: 138\n",
      "Número de classes cujos testes geraram exceptions: 0\n",
      "Número de classes cujos testes tiveram problemas de permissão: 61\n",
      "=======================================================================\n",
      "max mutation score: 100\n",
      "min mutation score: 0\n",
      "mean mutation score: 55.37\n",
      "number of NaN: 2\n",
      "=======================================================================\n",
      "max time_spent_to_execute_tests: 495.319 (seg)\n",
      "min time_spent_to_execute_tests: 0.0 (seg)\n",
      "mean time_spent_to_execute_tests: 116.0 (seg)\n",
      "number of NaN: 1\n",
      "=====================================================\n",
      "max test_suit_coverage: 100 (%)\n",
      "min test_suit_coverage: 0 (%)\n",
      "mean test_suit_coverage: 46.72 (%)\n",
      "number of NaN: 1\n",
      "=====================================================\n",
      "max coverage_of_criterion_no_unity: 100 (%)\n",
      "min coverage_of_criterion_no_unity: 0 (%)\n",
      "mean coverage_of_criterion_no_unity: 46.07 (%)\n",
      "number of NaN: 1\n",
      "=====================================================\n",
      "GA - métricas:\n",
      "=====================================================\n",
      "max search_finished_after_no_unity: 589 (s)\n",
      "min search_finished_after_no_unity: 0 (s)\n",
      "mean search_finished_after_no_unity: 162.89 (s)\n",
      "number of NaN: 1\n",
      "=====================================================\n",
      "max num_generations: 4870.0\n",
      "min num_generations: 0.0\n",
      "mean num_generations: 272.43\n",
      "number of NaN: 1\n",
      "=====================================================\n",
      "max num_statements: 947982.0\n",
      "min num_statements: 0.0\n",
      "mean num_statements: 199402.43\n",
      "number of NaN: 1\n",
      "=====================================================\n",
      "max best_ind_fitness: 3991.77\n",
      "min best_ind_fitness: 0.0\n",
      "mean best_ind_fitness: 414.41\n",
      "number of NaN: 1\n",
      "=====================================================\n",
      "=====================================================\n",
      "=====================================================\n",
      "Tempo Geral\n",
      "sum time_spent_to_execute_tests: 4.78 (horas)\n",
      "sum search_finished_after_no_unity: 6.7 (horas)\n",
      "=====================================================\n",
      "=====================================================\n",
      "=====================================================\n"
     ]
    }
   ],
   "source": [
    "analisa_csv(strongcsv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nesse ponto vale a pena mostrar os 3 csvs completos para o chain."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Next steps"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Rodar os casos de teste para o conjunto de dados após o bug-fix."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problemas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tentamos usar os scripts do defects4J para executar os casos de teste (d4j_test.pl e defects4j test) gerados mas a ferramenta apresentou alguns problemas que serão relatados."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### d4j_test.pl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ao tentar executar o script: **d4j_test.pl** com o comando abaixo:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "``` bash\n",
    "/home/sin5022-adm/defects4j/framework/bin/d4j/d4j_test.pl  -w /home/evosuite/adilsonTeste/Clojure_18_bug -s outputTeste/Closure/evosuite-branch/1/Closure-18b-evosuite-branch.1.tar.bz2\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Obtivemos o seguinte erro:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![alt text](pic/d4j_testpl.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Indicando a falta de algumas bibliotecas *Constant module*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### defects4j test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ao tentar executar o script: **defects4j test** com o comando abaixo:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "``` bash\n",
    "/home/sin5022-adm/defects4j/framework/bin/defects4j test -w /home/evosuite/adilsonTeste/Clojure_18_bug -s /home/evosuite/adilsonTeste/outputTeste/Closure/evosuite-branch/1/Closure-18b-evosuite-branch.1.tar.bz2\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Obtivemos o seguinte erro:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![alt text](pic/defects4j_test.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Indicando que não consegue extrair o casos de teste. Os quais estão no formato solicitados pela doc ([doc_defects4J](https://people.cs.umass.edu/~rjust/defects4j/html_doc/d4j/d4j-test.html)) da ferramenta: **Closure-18b-evosuite-branch.1.tar.bz2**. De acordo com essa doc o formato é: *project_id-version_id-test_suite_src.test_id.tar.bz2*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Seguem alguns exemplos:\n",
    "\n",
    "1. Lang-11f-randoop.1.tar.bz2\n",
    "2. Lang-12b-evosuite-weakmutation.1.tar.bz2\n",
    "3. Lang-12f-evosuite-branch.1.tar.bz2\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-09T13:47:44.194098Z",
     "start_time": "2019-06-09T13:47:44.147038Z"
    }
   },
   "source": [
    "# Chamando Junity na mão"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Coloquei os jars do evosuite no classpath do compilador **javac** com o comando:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "``` bash\n",
    "javac -cp .:\"junit-4.12.jar:evosuite-1.0.6.jar\"\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Em seguida adicionamos o caminho absoluto das classes **java** que devem ser compiladas:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "``` bash\n",
    "javac -cp .:\"junit-4.12.jar:evosuite-1.0.6.jar:\" testeJunity/main/java/outropackage/inside1/mult.java testeJunity/main/java/outropackage/ddd.java testeJunity/main/java/projetoCobertura/projetoCobertura/FmtRewrap.java testeJunity/test/java/projetoCobertura/projetoCobertura/FmtRewrapTeste.java\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compilamos, em seguida vamos executar o Junity para a classe de teste **projetoCobertura.projetoCobertura.FmtRewrapTeste**:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "``` bash\n",
    "java -cp .:\"junit-4.12.jar:evosuite-1.0.6.jar:./testeJunity/test/java/:./testeJunity/main/java/\" org.junit.runner.JUnitCore projetoCobertura.projetoCobertura.FmtRewrapTeste\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vale ressaltar os seguintes pontos:\n",
    "\n",
    "1. O nome da classe de teste deve contar apenas o path relativo a classe para o projeto e não o caminho absoluto do arquivo no filesystem.\n",
    "\n",
    "2. No classpath adicionamos o Junity, a raiz do projeto onde há o teste, a raiz do projeto onde está a classe de teste (ambos em relação ao filesystem)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Segue o output do Junity:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![alt text](pic/outputJunity.png)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Agora vamos executar para o projeto no servidor...."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Observações"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vale ressaltar um bug no evosuite que não permite a execução de algumas classes ao invocar o Junity $4$ por linha de comando, "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Rodando (MAC OS local) os testes unitários gerados no Lucy para a versão bug"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Uma classe não compila: **Graph_ESTest.java** segue abaixo o erro de execução encontrado:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-13T12:23:34.229269Z",
     "start_time": "2019-06-13T12:23:34.027352Z"
    }
   },
   "source": [
    "``` bash\n",
    "javac -cp .:\"junit-4.12.jar:evosuite-1.0.6.jar:./Clojure_18_bug/build/compiler.jar:./outputTeste/Closure/evosuite-branch/1/com/google/javascript/jscomp/\" $(find outputTeste/Closure/evosuite-branch/1/ -name \"*.java\")\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![alt text](pic/erroComp.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Removendo a classe com erro:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "``` bash\n",
    "--Removi a classe com erro\n",
    "javac -cp .:\"junit-4.12.jar:evosuite-1.0.6.jar:./Clojure_18_bug/build/compiler.jar:./outputTeste/Closure/evosuite-branch/1/com/google/javascript/jscomp/\" $(find outputTeste/Closure/evosuite-branch/1/ -name \"*.java\" -and -not -name \"Graph_ESTest.java\")\n",
    "``` "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "foi possível compilar perfeitamente, em seguida executamos as classes de teste geradas pelo evouite sobre a "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Rodando (MAC OS local) os testes unitários gerados no Lucy para a versão fixed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
